
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Real-time Transcription and Translation</title>
    <script src="https://cdn.socket.io/4.4.1/socket.io.min.js"></script>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: #333;
            margin: 0;
            padding: 20px;
            background-color: #f5f5f5;
        }
        .container {
            max-width: 1000px;
            margin: 0 auto;
            background: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 0 10px rgba(0,0,0,0.1);
        }
        h1 {
            text-align: center;
            color: #2c3e50;
            margin-bottom: 30px;
        }
        .controls {
            margin-bottom: 20px;
            display: flex;
            justify-content: space-between;
            align-items: center;
            flex-wrap: wrap;
            gap: 10px;
        }
        .language-select {
            display: flex;
            gap: 15px;
            align-items: center;
        }
        select, button {
            padding: 10px 15px;
            border: 1px solid #ddd;
            border-radius: 5px;
            font-size: 14px;
            outline: none;
        }
        button {
            background-color: #3498db;
            color: white;
            border: none;
            cursor: pointer;
            transition: background-color 0.3s;
        }
        button:hover {
            background-color: #2980b9;
        }
        button:disabled {
            background-color: #95a5a6;
            cursor: not-allowed;
        }
        .transcription-area {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 20px;
            margin-bottom: 20px;
        }
        .panel {
            background-color: white;
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 15px;
            min-height: 200px;
            max-height: 400px;
            overflow-y: auto;
        }
        .panel h3 {
            margin-top: 0;
            padding-bottom: 10px;
            border-bottom: 1px solid #eee;
            color: #2c3e50;
        }
        .status {
            text-align: center;
            margin-top: 20px;
            font-weight: bold;
        }
        .recording {
            animation: pulse 1.5s infinite;
            color: #e74c3c;
        }
        @keyframes pulse {
            0% { opacity: 1; }
            50% { opacity: 0.5; }
            100% { opacity: 1; }
        }
        
        /* New styles for improved UI */
        .interim {
            color: #666;
            font-style: italic;
        }

        .final {
            color: #000;
            font-weight: normal;
        }

        .error-message {
            color: #e74c3c;
            background-color: #fadbd8;
            padding: 10px;
            border-radius: 5px;
            margin-bottom: 10px;
        }

        .audio-level {
            height: 20px;
            background-color: #eee;
            border-radius: 10px;
            margin-top: 10px;
            overflow: hidden;
            position: relative;
        }

        .audio-level-bar {
            height: 100%;
            background-color: #3498db;
            width: 0%;
            transition: width 0.1s ease;
        }

        .settings-panel {
            margin-top: 20px;
            padding: 15px;
            border: 1px solid #ddd;
            border-radius: 5px;
            background-color: #f9f9f9;
        }

        .hidden {
            display: none;
        }
        
        /* Responsive design */
        @media (max-width: 768px) {
            .transcription-area {
                grid-template-columns: 1fr;
            }
            .controls {
                flex-direction: column;
                align-items: stretch;
            }
            .language-select {
                flex-direction: column;
                align-items: flex-start;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Real-time Transcription and Translation</h1>
        
        <div class="controls">
            <div class="language-select">
                <div>
                    <label for="from-lang">From:</label>
                    <select id="from-lang">
                        <option value="en-US">English (US)</option>
                        <option value="es-ES">Spanish</option>
                        <option value="fr-FR">French</option>
                        <option value="de-DE">German</option>
                        <option value="it-IT">Italian</option>
                        <option value="ja-JP">Japanese</option>
                        <option value="ko-KR">Korean</option>
                        <option value="pt-BR">Portuguese (Brazil)</option>
                        <option value="ru-RU">Russian</option>
                        <option value="zh-CN">Chinese (Simplified)</option>
                    </select>
                </div>
                <div>
                    <label for="to-lang">To:</label>
                    <select id="to-lang">
                        <option value="es">Spanish</option>
                        <option value="en">English</option>
                        <option value="fr">French</option>
                        <option value="de">German</option>
                        <option value="it">Italian</option>
                        <option value="ja">Japanese</option>
                        <option value="ko">Korean</option>
                        <option value="pt">Portuguese</option>
                        <option value="ru">Russian</option>
                        <option value="zh">Chinese (Simplified)</option>
                    </select>
                </div>
            </div>
            <div>
                <button id="start-btn">Start Transcription</button>
                <button id="stop-btn" disabled>Stop Transcription</button>
            </div>
        </div>
        
        <div class="transcription-area">
            <div class="panel">
                <h3>Original Text</h3>
                <div id="transcription"></div>
            </div>
            <div class="panel">
                <h3>Translation</h3>
                <div id="translation"></div>
            </div>
        </div>
        
        <div class="status" id="status">Ready to start</div>
        
        <div class="audio-level">
            <div class="audio-level-bar" id="audio-level-bar"></div>
        </div>

        <div class="settings-panel hidden" id="settings-panel">
            <h3>Advanced Settings</h3>
            <div>
                <label for="buffer-size">Buffer Size:</label>
                <select id="buffer-size">
                    <option value="256">256 (lowest latency, may be unstable)</option>
                    <option value="512">512 (low latency)</option>
                    <option value="1024">1024 (balanced)</option>
                    <option value="2048" selected>2048 (default)</option>
                    <option value="4096">4096 (high stability)</option>
                </select>
            </div>
            <div>
                <label for="sample-rate">Sample Rate:</label>
                <select id="sample-rate">
                    <option value="8000">8 kHz (lower quality)</option>
                    <option value="16000" selected>16 kHz (recommended for speech)</option>
                    <option value="24000">24 kHz</option>
                    <option value="44100">44.1 kHz (high quality)</option>
                    <option value="48000">48 kHz (highest quality)</option>
                </select>
            </div>
            <button id="toggle-advanced">Hide Advanced Settings</button>
        </div>

        <button id="show-advanced">Show Advanced Settings</button>
    </div>

    <script>
        // Initialize Socket.IO connection
        const socket = io();
        
        // DOM elements
        const startBtn = document.getElementById('start-btn');
        const stopBtn = document.getElementById('stop-btn');
        const fromLangSelect = document.getElementById('from-lang');
        const toLangSelect = document.getElementById('to-lang');
        const transcriptionDiv = document.getElementById('transcription');
        const translationDiv = document.getElementById('translation');
        const statusDiv = document.getElementById('status');
        const audioLevelBar = document.getElementById('audio-level-bar');
        const showAdvancedBtn = document.getElementById('show-advanced');
        const toggleAdvancedBtn = document.getElementById('toggle-advanced');
        const settingsPanel = document.getElementById('settings-panel');
        const bufferSizeSelect = document.getElementById('buffer-size');
        const sampleRateSelect = document.getElementById('sample-rate');
        
        // Audio context and variables
        let audioContext;
        let mediaStream;
        let processor;
        let input;
        let isRecording = false;
        let analyser = null;
        let bufferSize = 2048;
        let sampleRate = 16000;
        
        // Socket.IO event handlers
        socket.on('connect', () => {
            console.log('Connected to server');
        });
        
        socket.on('disconnect', () => {
            console.log('Disconnected from server');
            stopRecording();
        });
        
        // Handle interim results (while speaking)
        socket.on('interim_update', (data) => {
            // Update only the transcription panel with interim results
            // Only update if we're not showing a final result
            if (!transcriptionDiv.lastChild || !transcriptionDiv.lastChild.classList.contains('final')) {
                // If there's an existing interim element, update it
                if (transcriptionDiv.lastChild && transcriptionDiv.lastChild.classList.contains('interim')) {
                    transcriptionDiv.lastChild.textContent = data.transcription;
                } else {
                    // Create a new interim element
                    const interimElem = document.createElement('p');
                    interimElem.classList.add('interim');
                    interimElem.textContent = data.transcription;
                    transcriptionDiv.appendChild(interimElem);
                    transcriptionDiv.scrollTop = transcriptionDiv.scrollHeight;
                }
            }
        });
        
        // Update the transcription_update handler for final results
        socket.on('transcription_update', (data) => {
            // Remove any interim results
            if (transcriptionDiv.lastChild && transcriptionDiv.lastChild.classList.contains('interim')) {
                transcriptionDiv.removeChild(transcriptionDiv.lastChild);
            }
            
            // Add final results with distinct styling
            const transcriptionElem = document.createElement('p');
            transcriptionElem.classList.add('final');
            transcriptionElem.textContent = data.transcription;
            transcriptionDiv.appendChild(transcriptionElem);
            
            const translationElem = document.createElement('p');
            translationElem.classList.add('final');
            translationElem.textContent = data.translation;
            translationDiv.appendChild(translationElem);
            
            // Scroll to bottom
            transcriptionDiv.scrollTop = transcriptionDiv.scrollHeight;
            translationDiv.scrollTop = translationDiv.scrollHeight;
        });
        
        socket.on('transcription_status', (data) => {
            if (data.status === 'started') {
                statusDiv.innerHTML = 'Recording... <span class="recording">●</span>';
                statusDiv.classList.add('recording');
                startBtn.disabled = true;
                stopBtn.disabled = false;
            } else if (data.status === 'stopped') {
                statusDiv.innerHTML = 'Ready to start';
                statusDiv.classList.remove('recording');
                startBtn.disabled = false;
                stopBtn.disabled = true;
                stopRecording();
            }
        });
        
        socket.on('error', (data) => {
            console.error(data.message);
            const errorDiv = document.createElement('div');
            errorDiv.classList.add('error-message');
            errorDiv.textContent = data.message;
            document.querySelector('.container').insertBefore(errorDiv, statusDiv);
        });
        
        // Show/hide advanced settings
        showAdvancedBtn.addEventListener('click', () => {
            settingsPanel.classList.remove('hidden');
            showAdvancedBtn.classList.add('hidden');
        });

        toggleAdvancedBtn.addEventListener('click', () => {
            settingsPanel.classList.add('hidden');
            showAdvancedBtn.classList.remove('hidden');
        });

        // Update settings when changed
        bufferSizeSelect.addEventListener('change', (e) => {
            bufferSize = parseInt(e.target.value);
        });

        sampleRateSelect.addEventListener('change', (e) => {
            sampleRate = parseInt(e.target.value);
        });

        // Add audio visualization
        function updateAudioLevel() {
            if (!analyser || !isRecording) return;
            
            const dataArray = new Uint8Array(analyser.fftSize);
            analyser.getByteTimeDomainData(dataArray);
            
            // Calculate audio level (0-100)
            let sum = 0;
            for (let i = 0; i < dataArray.length; i++) {
                sum += Math.abs(dataArray[i] - 128);
            }
            const average = sum / dataArray.length;
            const level = Math.min(100, average * 2);
            
            // Update visualization
            audioLevelBar.style.width = `${level}%`;
            
            // Request next frame
            if (isRecording) {
                requestAnimationFrame(updateAudioLevel);
            }
        }
        
        // Start recording and transcription
        startBtn.addEventListener('click', async () => {
            try {
                // Clear previous content
                transcriptionDiv.innerHTML = '';
                translationDiv.innerHTML = '';
                
                // Remove any error messages
                const errorMessages = document.querySelectorAll('.error-message');
                errorMessages.forEach(el => el.remove());
                
                // Get language preferences
                const fromLang = fromLangSelect.value;
                const toLang = toLangSelect.value;
                
                // Request microphone access with specific constraints
                const constraints = {
                    audio: {
                        channelCount: 1,           // Mono audio (important for speech recognition)
                        sampleRate: sampleRate,    // Sample rate from settings
                        sampleSize: 16,            // 16-bit samples
                        echoCancellation: true,    // Enable echo cancellation
                        noiseSuppression: true,    // Enable noise suppression
                        autoGainControl: true      // Enable automatic gain control
                    }
                };
                
                mediaStream = await navigator.mediaDevices.getUserMedia(constraints);
                
                // Start audio processing with improved settings
                audioContext = new (window.AudioContext || window.webkitAudioContext)({
                    sampleRate: sampleRate  // Force sample rate from settings
                });
                
                input = audioContext.createMediaStreamSource(mediaStream);
                
                // Create analyser for visualization
                analyser = audioContext.createAnalyser();
                analyser.fftSize = 256;
                input.connect(analyser);
                
                // Create processor with buffer size from settings
                processor = audioContext.createScriptProcessor(bufferSize, 1, 1);
                
                // Connect nodes
                input.connect(processor);
                processor.connect(audioContext.destination);
                
                // Start audio level visualization
                updateAudioLevel();
                
                // Process audio data with improved conversion
                processor.onaudioprocess = (e) => {
                    if (!isRecording) return;
                    
                    // Get audio data
                    const inputData = e.inputBuffer.getChannelData(0);
                    
                    // Convert to 16-bit PCM with proper scaling
                    const pcmData = convertFloat32ToInt16(inputData);
                    
                    // Send to server
                    socket.emit('audio_data', { audio_data: pcmData });
                };
                
                // Start recording
                isRecording = true;
                
                // Start transcription on the server
                socket.emit('start_transcription', { from_lang: fromLang, to_lang: toLang });
                
            } catch (error) {
                console.error('Error starting recording:', error);
                const errorDiv = document.createElement('div');
                errorDiv.classList.add('error-message');
                errorDiv.textContent = `Error: ${error.message}`;
                document.querySelector('.container').insertBefore(errorDiv, statusDiv);
            }
        });
        
        // Stop recording and transcription
        stopBtn.addEventListener('click', () => {
            socket.emit('stop_transcription');
            stopRecording();
        });
        
        // Helper function to stop recording
        function stopRecording() {
            isRecording = false;
            
            // Clean up audio resources
            if (processor) {
                processor.disconnect();
                processor = null;
            }
            
            if (analyser) {
                analyser.disconnect();
                analyser = null;
            }
            
            if (input) {
                input.disconnect();
                input = null;
            }
            
            if (audioContext && audioContext.state !== 'closed') {
                audioContext.close();
                audioContext = null;
            }
            
            if (mediaStream) {
                mediaStream.getTracks().forEach(track => track.stop());
                mediaStream = null;
            }
            
            // Update UI
            startBtn.disabled = false;
            stopBtn.disabled = true;
            audioLevelBar.style.width = '0%';
        }
        
        // Improved audio conversion function
        function convertFloat32ToInt16(buffer) {
            const l = buffer.length;
            const buf = new Int16Array(l);
            
            // Improved scaling for better audio quality
            for (let i = 0; i < l; i++) {
                // Apply proper scaling and clamping
                const s = Math.max(-1, Math.min(1, buffer[i]));
                // Convert to 16-bit signed integer
                buf[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
            }
            
            return buf.buffer;
        }
    </script>
</body>
</html>
        